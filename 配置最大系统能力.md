# 配置最大系统能力（Multi-Agent AI 特种战队）

> 目标：**最大化系统能力（System Capability）**，而非追求单一模型峰值性能。
>
> 适用场景：AutoGen / 多 Agent 框架；人类 Commander 具备最终裁决权。

---

## 1. 设计目标与形式化定义

### 1.1 系统能力定义

```
System Capability =
  问题空间覆盖率
× 失败模式发现概率
× 错误阻断概率
× 单位成本下的稳定性
```

**优化方向**：
- 不是减少错误生成，而是**降低高置信错误被发布的概率**。
- 通过“异构认知 + 强制冲突 + 条件化升级”实现。

---

## 2. 角色划分与职责边界

### 2.1 角色说明

| 角色 | 职责定位 | 是否具备否决权 |
|---|---|---|
| Commander（人类） | 定义价值函数、最终裁决 | 是（终极） |
| Planner | 扩展解空间、任务拆解 | 否 |
| Red Team | 收缩解空间、构造失败路径 | 否（但可触发升级） |
| Executor | 工程化执行、工具调用 | 否 |
| Auditor | 判定是否放行 | 是（流程级） |

---

## 3. 模型配置（最大系统能力解）

### 3.1 主模型 + 触发模型配置表

| Agent | 主模型 | 触发模型 | 系统作用说明 |
|---|---|---|---|
| Planner | Claude 4.5 | GPT-5.2 | 扩展解空间；GPT 用于战略校验 |
| Red Team | DeepSeek-R1 | Claude 4.5 | 高强度反例构造；复杂攻击补强 |
| Peer Analyst | GPT-4o | Claude 3.5 Sonnet | 建设性分析；复杂价值评估补强 |
| Executor | GPT-5.2 | GPT-4.1 | 工程与工具成功率优先 |
| Auditor | DeepSeek-R1 | GPT-5.2 | 严苛否决；不可逆决策终审 |
| Commander | 人类 | GPT-5.2（咨询） | 价值判断与责任归属 |

> 原则：**最强模型不常驻，仅在关键节点触发。**

---

## 4. 交互拓扑与回合控制（强约束）

### 4.1 固定流程（禁止自由对话）

```
Commander → Planner
Planner → Red Team
Red Team → Peer Analyst（平衡分析）
Peer Analyst → Commander（全面评估）
Commander → Executor
Executor → Auditor
Auditor → Commander（是否放行）
```

### 4.2 关键约束

- Red Team **不得**直接影响 Executor。
- Peer Analyst **不得**重复 Red Team 的负面攻击，必须提供建设性分析。
- Auditor **只给结论与证据**，不提出新方案。
- Commander **不参与内容细节生成**，只裁决。

---

## 5. 触发式升级规则（核心机制）

### 5.1 Planner → GPT-5.2 升级条件

- 方案影响范围：高（资金、生产、发布、删除）
- 决策不可逆
- Red Team 提出 ≥ 2 条结构性风险

### 5.2 Red Team → Claude 4.5 升级条件

- DeepSeek-R1 无法构造有效反例
- 方案依赖隐含假设（assumption-heavy）
- Planner 使用类比或高度抽象推理

### 5.3 Peer Analyst → Claude 3.5 Sonnet 升级条件

- 方案价值评估复杂度高（多维度权衡）
- 需要深度行业洞察或专业知识
- Red Team 攻击与方案优势冲突明显
- 人类 Commander 要求更高置信度分析

### 5.4 Auditor 强制终审条件

- 判定为“不通过”
- 或“通过但置信度 < 0.7”

→ **强制触发 GPT-5.2 终审**

---

## 6. 否决权与责任设计

### 6.1 否决层级

| 层级 | 否决对象 | 是否可被推翻 |
|---|---|---|
| Auditor | 执行结果 | 可（仅 Commander） |
| Commander | 全流程 | 否 |

### 6.2 责任原则

- AI Agent **不承担责任**
- 所有不可逆决策需 Commander 显式确认

---

## 7. 常见失效模式与防护

| 失效模式 | 根因 | 防护机制 |
|---|---|---|
| 红队不够狠 | 模型同质化 | 异构模型 + 升级触发 |
| 审计放水 | 无否决权 | Auditor 独立裁决 |
| 成本失控 | 强模型常驻 | 条件化调用 |
| 自信型错误 | 高一致性模型 | 强制冲突与人类裁决 |

---

## 8. 工程落地建议

1. **先实现流程约束，再调模型能力**
2. **日志必须可回放（每轮决策留痕）**
3. **Auditor 输出结构化结论（通过 / 不通过 + 证据）**

---

## 9. 一句话作战条令

> **最大系统能力 = 异构认知 × 强制冲突 × 条件化最强模型 × 人类裁决**

---

（完）

